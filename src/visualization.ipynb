{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82b7ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/datalab/notebooks/Adam/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gunet import GUNet\n",
    "from unet import UNet\n",
    "from dataset import CustomDataset, get_images\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "from torchsummary import summary\n",
    "import scipy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8280db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import torchvision.transforms.functional as TF\n",
    "image = Image.open('radar_aeroporto.jpeg')\n",
    "image = ImageOps.grayscale(image)\n",
    "\n",
    "original_tensor = TF.to_tensor(image)\n",
    "\n",
    "constatnt = 0.2\n",
    "\n",
    "# Add Gaussian noise to the image\n",
    "noisy_tensor = original_tensor + torch.randn(original_tensor.shape) * constatnt\n",
    "\n",
    "# Add a constant value to all pixels in the image\n",
    "value_tensor = original_tensor + constatnt\n",
    "\n",
    "# Add a batch dimension to the tensors\n",
    "original_tensor = original_tensor.unsqueeze(0)\n",
    "noisy_tensor = noisy_tensor.unsqueeze(0)\n",
    "value_tensor = value_tensor.unsqueeze(0)\n",
    "\n",
    "losses = [nn.L1Loss(), nn.MSELoss(), pytorch_ssim.SSIM(window_size=11)]\n",
    "\n",
    "num_images = 2\n",
    "num_losses = len(losses)\n",
    "loss_array = np.zeros((num_images, num_losses))\n",
    "\n",
    "# Compute the losses for each modified image\n",
    "for i, (name, tensor) in enumerate([('Noisy', noisy_tensor), ('Value', value_tensor)]):\n",
    "    for j, loss_fn in enumerate(losses):\n",
    "        loss = loss_fn(original_tensor, tensor).item()\n",
    "        loss_array[i, j] = loss\n",
    "print(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e61d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.colors as colors\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "coor = (11.8, 48.07, 19.41, 51.57)\n",
    "\n",
    "idx = [1,3,5,7]\n",
    "# ratio = targets[0,0].shape[0]/targets[0,0].shape[1]\n",
    "ratio = image.height / image.width\n",
    "\n",
    "fig,axs = plt.subplots(1,3, dpi=200, figsize=(9,3),height_ratios=[ratio])\n",
    "\n",
    "cmap = 'gray'\n",
    "\n",
    "images = []\n",
    "\n",
    "\n",
    "axs[1].set_xlabel(r\"$\\bf{SSIM}: $\" + f\"{loss_array[0,2]:.3f}, \" + \n",
    "                    r\"$\\bf{MAE}: $\" + f\"{loss_array[0,0]:.3f}, \" +\n",
    "                    r\"$\\bf{MSE}: $\" + f\"{loss_array[0,1]:.3f}\",labelpad=0)\n",
    "axs[2].set_xlabel(r\"$\\bf{SSIM}: $\" + f\"{loss_array[1,2]:.3f}, \" + \n",
    "                    r\"$\\bf{MAE}: $\" + f\"{loss_array[1,0]:.3f}, \" +\n",
    "                    r\"$\\bf{MSE}: $\" + f\"{loss_array[1,1]:.3f}\",labelpad=0)\n",
    "axs[0].imshow(original_tensor[0,0],cmap=cmap)\n",
    "axs[1].imshow(noisy_tensor[0,0],cmap=cmap)\n",
    "axs[2].imshow(value_tensor[0,0],cmap=cmap)\n",
    "    \n",
    "    \n",
    "# for axs2 in axs:\n",
    "#     for ax in axs2:\n",
    "#         ax.set_frame_on(False)\n",
    "        \n",
    "\n",
    "    \n",
    "for ax, title in zip(axs, [\"Original\", \"Added\\ noise\", \"Added\\ constant\"]):\n",
    "    ax.set_title(r\"$\\bf{\"+f\"{title}\"+\"}$\")\n",
    "    ax.set_frame_on(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout(pad=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31009f9-b776-4ea2-9a19-4015c11b1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465fc07-34c1-4339-b56c-b76a557d1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/datalab/notebooks/Adam/run/unet_without_clr/dataset_config.yaml') as file:\n",
    "    dataset_config = yaml.safe_load(file)\n",
    "\n",
    "with open('/home/datalab/notebooks/Adam/run/unet_without_clr/model_config.yaml') as file:\n",
    "    unet_config = yaml.safe_load(file)\n",
    "\n",
    "with open('/home/datalab/notebooks/Adam/run/gunet_without_clr/model_config.yaml') as file:\n",
    "    gunet_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = get_images(dataset_config['data_path'],\n",
    "                                                            dataset_config['stride_minutes'],\n",
    "                                                            dataset_config['input_length'],\n",
    "                                                            dataset_config['output_length'],\n",
    "                                                            dataset_config['chunk_size'],\n",
    "                                                            dataset_config['test_frac'],\n",
    "                                                            dataset_config['val_frac'],\n",
    "                                                            dataset_config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "#     transforms.CenterCrop((256, 512)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "        \n",
    "dataset = CustomDataset(X_test, y_test,transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=gunet_config['batch_size'], shuffle=True, num_workers=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf51a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(CustomDataset(X_train, y_train,transform=transform), batch_size=1, shuffle=True, num_workers=16,)\n",
    "val_loader = DataLoader(CustomDataset(X_val, y_val,transform=transform), batch_size=1, shuffle=False, num_workers=16,)\n",
    "test_loader = DataLoader(CustomDataset(X_test, y_test,transform=transform), batch_size=50, shuffle=False, num_workers=16,)\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "#168110 21108 20957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunet_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7599b-c448-40d4-8d45-31066636e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d35e9-3636-43b7-92b0-a08251db91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunet_model = GUNet(dataset_config['input_length'], dataset_config['output_length'], gunet_config['dropout_rate'], gunet_config['r'], gunet_config['epsilon'])\n",
    "gunet_model.to(device)\n",
    "path = f\"/home/datalab/notebooks/Adam/run/gunet_without_clr/models/best.pt\"\n",
    "gunet_model.load_state_dict(torch.load(path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f2009-a744-40fb-8f5f-79f080671406",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = UNet(dataset_config['input_length'], dataset_config['output_length'],unet_config['dropout_rate'],k=unet_config['kernel_size'])\n",
    "unet_model.to(device)\n",
    "path = f\"/home/datalab/notebooks/Adam/run/unet_without_clr/models/best.pt\"\n",
    "unet_model.load_state_dict(torch.load(path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunet_model.eval()\n",
    "unet_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f13aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(c):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    ssim_loss = pytorch_ssim.SSIM()\n",
    "    mae_loss = nn.L1Loss()\n",
    "    losses = [mae_loss,mse_loss,ssim_loss]\n",
    "\n",
    "\n",
    "    running_losses_gunet_sum = np.zeros(len(losses))\n",
    "    running_losses_unet_sum = np.zeros(len(losses))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(c):\n",
    "        running_losses_gunet = np.zeros(len(losses))\n",
    "        running_losses_unet = np.zeros(len(losses))\n",
    "        batch_size = 50\n",
    "        test_loader = iter(DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=32,))\n",
    "        with torch.no_grad():\n",
    "            for (inputs, targets) in tqdm(test_loader, \"Testing\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                gunet_outputs = gunet_model(inputs)\n",
    "                unet_outputs = unet_model(inputs)\n",
    "\n",
    "                for k in range(len(losses)):\n",
    "                    running_losses_gunet[k] += losses[k](gunet_outputs, targets).item()\n",
    "                    running_losses_unet[k] += losses[k](unet_outputs, targets).item()\n",
    "        print(f'GUNet: {\", \".join([f\"{i:.7f}\" for i in running_losses_gunet/len(test_loader)])}')\n",
    "        print(f'UNet: {\", \".join([f\"{i:.7f}\" for i in running_losses_unet/len(test_loader)])}')\n",
    "        running_losses_gunet_sum +=  running_losses_gunet\n",
    "        running_losses_unet_sum +=  running_losses_unet\n",
    "        print(f'sum GUNet: {\", \".join([f\"{i:.7f}\" for i in running_losses_gunet_sum/(len(test_loader)*(i+1))])}')\n",
    "        print(f'sum UNet: {\", \".join([f\"{i:.7f}\" for i in running_losses_unet_sum/(len(test_loader)*(i+1))])}')\n",
    "        print('---------------')\n",
    "    return running_losses_gunet_sum, running_losses_unet_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loss_gunet, run_loss_unet = measure(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_with_thresholds(c):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    ssim_loss = pytorch_ssim.SSIM()\n",
    "    mae_loss = nn.L1Loss()\n",
    "    losses = [mae_loss,mse_loss,ssim_loss]\n",
    "\n",
    "    step = 1/c\n",
    "    threshold = 0\n",
    "    dic_unet = {}\n",
    "    dic_gunet = {}\n",
    "    for i in range(c+1):\n",
    "        running_losses_gunet = np.zeros(len(losses))\n",
    "        running_losses_unet = np.zeros(len(losses))\n",
    "        batch_size = 40\n",
    "        test_loader = iter(DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=32,))\n",
    "        with torch.no_grad():\n",
    "            for (inputs, targets) in tqdm(test_loader, f\"Testing {threshold}\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                gunet_outputs = gunet_model(inputs)\n",
    "                unet_outputs = unet_model(inputs)\n",
    "                \n",
    "                targets.masked_fill_(targets < threshold, 0)\n",
    "                gunet_outputs.masked_fill_(gunet_outputs < threshold, 0)\n",
    "                unet_outputs.masked_fill_(unet_outputs < threshold, 0)\n",
    "                \n",
    "                for k in range(len(losses)):\n",
    "                    running_losses_gunet[k] += losses[k](gunet_outputs, targets).item()\n",
    "                    running_losses_unet[k] += losses[k](unet_outputs, targets).item()\n",
    "                    \n",
    "        dic_unet[threshold] = running_losses_unet/len(test_loader)\n",
    "        dic_gunet[threshold] = running_losses_gunet/len(test_loader)\n",
    "        print(f'GUNet: {\", \".join([f\"{i:.7f}\" for i in running_losses_gunet/len(test_loader)])}') \n",
    "        print(f'UNet: {\", \".join([f\"{i:.7f}\" for i in running_losses_unet/len(test_loader)])}')\n",
    "        threshold += step\n",
    "\n",
    "    return dic_unet, dic_gunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48fd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_unet, dic_gunet = measure_with_thresholds(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7491a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unet = pd.DataFrame(dic_unet).transpose()\n",
    "df_unet.rename(columns={0:'mae_unet',1:'mse_unet',2:'ssim_unet'},inplace=True)\n",
    "df_unet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87185963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gunet = pd.DataFrame(dic_gunet).transpose()\n",
    "df_gunet.rename(columns={0:'mae_gunet',1:'mse_gunet',2:'ssim_gunet'},inplace=True)\n",
    "df_gunet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_unet.join(df_gunet)\n",
    "df = df.sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as olorbar\n",
    "\n",
    "def threshold_plot(loss,cmap,reverse):\n",
    "    y = (df[f'{loss}_gunet']-df[f'{loss}_unet']).to_numpy()\n",
    "    x = df.index\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,dpi=200,figsize=(7,3))\n",
    "\n",
    "    axs[0].plot(df[f'{loss}_unet'],c=\"#268BD2\",label='Unet',)\n",
    "    axs[0].plot(df[f'{loss}_gunet'],c=\"#D1495B\",label='GUnet',ls=\"--\")\n",
    "\n",
    "    axs[0].set_xlim(0.0,1)\n",
    "    axs[0].legend(framealpha=1)\n",
    "    axs[0].grid(True,c='0.8')\n",
    "    axs[0].set_frame_on(False)\n",
    "    axs[0].set_xlabel('Threshold')\n",
    "    axs[0].set_ylabel(loss.upper())\n",
    "\n",
    "\n",
    "    cmap = cm.get_cmap(cmap)\n",
    "\n",
    "    vmin = -max(abs(np.max(y)),abs(np.min(y)))\n",
    "    vmax = max(abs(np.max(y)),abs(np.min(y)))\n",
    "\n",
    "\n",
    "    axs[1].plot(x, y, c='#EDAE49', linewidth=2)\n",
    "\n",
    "    axs[1].set_frame_on(False)\n",
    "    axs[1].set_xlabel('Threshold')\n",
    "    axs[1].set_ylabel('Difference',labelpad=0)\n",
    "    axs[1].grid(True,c='0.8')\n",
    "    axs[1].set_ylim(vmin-0.1*abs(vmin),vmax+0.1*abs(vmax))\n",
    "\n",
    "    fig.tight_layout(pad=2)\n",
    "\n",
    "#     fig.colorbar(dummy_scatter,ax=axs,shrink=1,location='right', orientation='vertical',pad=0.05)\n",
    "    \n",
    "    \n",
    "threshold_plot('mse','coolwarm',False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb10524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.scale as mscale\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "fig, ax = plt.subplots(1,1,dpi=200,figsize=(6,6))\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "ax.plot(df['ssim_unet']-df['ssim_gunet'],c=\"#268BD2\")\n",
    "# ax.plot(10**df['ssim_gunet'],c=\"#D1495B\",label='GUnet',lw=0.5)\n",
    "\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('SSIM')\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "\n",
    "# y_ticks = np.arange(0.825, 0.875, 0.01)\n",
    "# plt.yticks(y_ticks,[round(i,3) if round(i,4) % 0.001 == 0 else \"\"  for i in y_ticks])\n",
    "# ax.set_xticks([i * 86400 for i in np.arange(0,3.5,0.5)])\n",
    "# ax.set_xticklabels([f\"{round(i // 3600)}\" for i in ax.get_xticks()])\n",
    "# ax.set_xlim(0.25,0.35)\n",
    "# ax.set_ylim(0.93,0.96)\n",
    "# ax.set_yscale('log')\n",
    "ax.legend(framealpha=1)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "ax.grid(True,c='0.8')\n",
    "ax.set_frame_on(False)\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = tuple(inputs.shape[1:])\n",
    "# print(size)\n",
    "# unet_model.to('cpu')\n",
    "# summary(unet_model,size,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = tuple(inputs.shape[1:])\n",
    "# print(size)\n",
    "# gunet_model.to('cpu')\n",
    "# summary(gunet_model,size,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30952c60-1226-4807-8390-5612676df161",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accumulate(loader):\n",
    "    unet_acc_out = None\n",
    "    gunet_acc_out = None\n",
    "    acc_tar = None\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(loader, desc=\"Accumulating\"):\n",
    "            batch_size = inputs.size(0)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs_unet = unet_model(inputs)\n",
    "            outputs_gunet = gunet_model(inputs)\n",
    "\n",
    "            batch_unet_acc_out = outputs_unet.sum(dim=(0, 1))\n",
    "            batch_gunet_acc_out = outputs_gunet.sum(dim=(0, 1))\n",
    "            batch_acc_tar = targets.sum(dim=(0, 1))\n",
    "\n",
    "            if count == 0:\n",
    "                unet_acc_out = batch_unet_acc_out\n",
    "                gunet_acc_out = batch_gunet_acc_out\n",
    "                acc_tar = batch_acc_tar\n",
    "            else:\n",
    "                unet_acc_out += batch_unet_acc_out\n",
    "                gunet_acc_out += batch_gunet_acc_out\n",
    "                acc_tar += batch_acc_tar\n",
    "\n",
    "            count += outputs_unet.size(0) * outputs_unet.size(1)\n",
    "    return acc_tar / count, unet_acc_out / count, gunet_acc_out / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar, unet_out, gunet_out = accumulate(loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7614ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, window_size=32):\n",
    "    window = np.ones((window_size,window_size)) / window_size**2\n",
    "    \n",
    "    return scipy.signal.convolve2d(arr, window, mode='same')\n",
    "\n",
    "def transforms(arr):\n",
    "    tmp = np.fft.fftshift(torch.fft.fftn(arr))\n",
    "    return np.log(np.abs(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3),dpi=200)\n",
    "# ax1 = fig.add_subplot(1,2,1,projection='3d')\n",
    "ax2 = fig.add_subplot(1,2,1,projection='3d')\n",
    "ax3 = fig.add_subplot(1,2,2,projection='3d')\n",
    "\n",
    "\n",
    "r = range(0, tar.shape[1])\n",
    "p = range(0, tar.shape[0])\n",
    "X, Y = np.meshgrid(r, p)\n",
    "\n",
    "z1 = moving_average(transforms(tar.cpu()))\n",
    "z2 = moving_average(transforms(gunet_out.cpu()))\n",
    "z3 = moving_average(transforms(unet_out.cpu()))\n",
    "vmin=0.9\n",
    "vmax=1.9\n",
    "print(vmin,vmax)\n",
    "# ax1.plot_surface(X, Y, abs(z1-z1), cmap='turbo', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "ax2.plot_surface(X, Y, abs(z2-z1), cmap='RdYlGn_r', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "ax3.plot_surface(X, Y, abs(z3-z1), cmap='RdYlGn_r', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "\n",
    "# ax1.set_title(\"Targets\")\n",
    "ax2.set_title(\"GUNet\")\n",
    "ax3.set_title(\"UNet\")\n",
    "\n",
    "for ax in [ax2,ax3]:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zlim(vmin, vmax+1.5)\n",
    "    \n",
    "\n",
    "# ax.set_xlabel(\"X label\")\n",
    "# ax.set_ylabel(\"Y label\")\n",
    "# ax.set_zlabel(\"Z label\")\n",
    "ax2.set_zlim(vmin, vmax+1.5)\n",
    "ax3.set_zlim(vmin, vmax+1.5)\n",
    "\n",
    "# plt.imshow(transforms(gunet_out.cpu()),cmap='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,5),dpi=200)\n",
    "# axs[0].imshow(z1,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[0].imshow(abs(z2-z1),vmin=vmin,vmax=vmax,cmap='RdYlGn_r')\n",
    "axs[1].imshow(abs(z3-z1),vmin=vmin,vmax=vmax,cmap='RdYlGn_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin=-3\n",
    "vmax=1\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,5),dpi=200)\n",
    "axs[0].imshow(z1,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[1].imshow(z2,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[2].imshow(z3,vmin=vmin,vmax=vmax,cmap='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([z1.flatten(),z2.flatten(),z3.flatten()],bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d171e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8,4),dpi=200)\n",
    "# axs[0].imshow(z1,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[0].imshow(abs(z2-z1),vmin=vmin,vmax=vmax,cmap='RdYlGn_r')\n",
    "axs[1].imshow(abs(z3-z1),vmin=vmin,vmax=vmax,cmap='RdYlGn_r')\n",
    "\n",
    "for ax, title in zip(axs, [\"UNet\", \"GUNet\"]):\n",
    "    ax.set_title(r\"$\\bf{\"+f\"{title}\"+\"}$\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "fig.tight_layout(pad=1)\n",
    "fig.colorbar(s, ax=axs,shrink=0.5,location='bottom', orientation='horizontal',pad=0.05)\n",
    "\n",
    "fig,axs = plt.subplots(1,3, dpi=200, figsize=(3,1), height_ratios=[ratio])\n",
    "\n",
    "axs[0].imshow(gunet_out.cpu(),cmap='turbo')\n",
    "axs[1].imshow(unet_out.cpu(),cmap='turbo')\n",
    "axs[2].imshow(tar.cpu(),cmap='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76408d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff027762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(means_gunet, means_unet, alternative='greater')\n",
    "\n",
    "print(p_value)\n",
    "\n",
    "alpha = 0.05  # Set significance level (e.g., 0.05 for 95% confidence)\n",
    "if p_value < alpha:\n",
    "    print(\"Model 1 generates images with significantly higher frequency content.\")\n",
    "    print(f\"We reject the null hypothesis (H0) in favor of the alternative hypothesis (H1) at a {100 * (1 - alpha)}% confidence level.\")\n",
    "else:\n",
    "    print(\"No significant difference in frequency content between the two models.\")\n",
    "    print(f\"We cannot reject the null hypothesis (H0) at a {100 * (1 - alpha)}% confidence level.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c163be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_random(batch_size, channels, height, width, max_batches):\n",
    "    unet_acc_out = None\n",
    "    gunet_acc_out = None\n",
    "    inputs_acc = None\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(max_batches), desc=\"Accumulating\"):\n",
    "            \n",
    "            inputs = torch.randn(batch_size, channels, height, width).to(device)\n",
    "            outputs_unet = unet_model(inputs)\n",
    "            outputs_gunet = gunet_model(inputs)\n",
    "\n",
    "            batch_unet_acc_out = outputs_unet.sum(dim=(0, 1))\n",
    "            batch_gunet_acc_out = outputs_gunet.sum(dim=(0, 1))\n",
    "            batch_inputs_acc = inputs.sum(dim=(0, 1))\n",
    "\n",
    "            if count == 0:\n",
    "                unet_acc_out = batch_unet_acc_out\n",
    "                gunet_acc_out = batch_gunet_acc_out\n",
    "                inputs_acc = batch_inputs_acc\n",
    "            else:\n",
    "                unet_acc_out += batch_unet_acc_out\n",
    "                gunet_acc_out += batch_gunet_acc_out\n",
    "                inputs_acc += batch_inputs_acc\n",
    "\n",
    "            count += outputs_unet.size(0) * outputs_unet.size(1)\n",
    "    return  unet_acc_out / count, gunet_acc_out / count, inputs_acc / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb532fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unet_rand,gunet_rand, in_rand = accumulate_random(50,8,256,512,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d2c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, window_size=32):\n",
    "    window = np.ones((window_size,window_size)) / window_size**2\n",
    "    \n",
    "    return scipy.signal.convolve2d(arr, window, mode='same')\n",
    "\n",
    "fig = plt.figure(figsize=(6,3),dpi=200)\n",
    "# ax1 = fig.add_subplot(1,2,1,projection='3d')\n",
    "ax2 = fig.add_subplot(1,2,1,projection='3d')\n",
    "ax3 = fig.add_subplot(1,2,2,projection='3d')\n",
    "\n",
    "\n",
    "r = range(0, in_rand.shape[1])\n",
    "p = range(0, in_rand.shape[0])\n",
    "X, Y = np.meshgrid(r, p)\n",
    "\n",
    "z1 = moving_average(transforms(in_rand.cpu()))\n",
    "z2 = moving_average(transforms(gunet_rand.cpu()))\n",
    "z3 = moving_average(transforms(unet_rand.cpu()))\n",
    "vmin=-3\n",
    "vmax=1\n",
    "print(vmin,vmax)\n",
    "# ax1.plot_surface(X, Y, abs(z1-z1), cmap='turbo', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "ax2.plot_surface(X, Y, z2, cmap='turbo', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "ax3.plot_surface(X, Y, z3, cmap='turbo', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "\n",
    "# ax1.set_title(\"Targets\")\n",
    "ax2.set_title(\"GUNet\")\n",
    "ax3.set_title(\"UNet\")\n",
    "\n",
    "for ax in [ax2,ax3]:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zlim(vmin, vmax+1.5)\n",
    "    \n",
    "\n",
    "# ax.set_xlabel(\"X label\")\n",
    "# ax.set_ylabel(\"Y label\")\n",
    "# ax.set_zlabel(\"Z label\")\n",
    "ax2.set_zlim(vmin, vmax+1.5)\n",
    "ax3.set_zlim(vmin, vmax+1.5)\n",
    "\n",
    "# plt.imshow(transforms(gunet_out.cpu()),cmap='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a511e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(arr):\n",
    "    tmp = torch.fft.fftshift(torch.fft.fftn(arr))\n",
    "    return tmp\n",
    "\n",
    "def accumulate_fourier(loader):\n",
    "    unet_acc_out = None\n",
    "    gunet_acc_out = None\n",
    "    acc_tar = None\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs, targets) in tqdm(loader, \"Accumulating\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs_unet = unet_model(inputs)\n",
    "            outputs_gunet = gunet_model(inputs)\n",
    "\n",
    "            for i in range(outputs_unet.shape[0]):\n",
    "                for j in range(outputs_unet.shape[1]):\n",
    "                    if count == 0:\n",
    "                        unet_acc_out = transforms(outputs_unet[i,j])\n",
    "                        gunet_acc_out = transforms(outputs_gunet[i,j])\n",
    "                        acc_tar = transforms(targets[i,j])\n",
    "                    else:\n",
    "                        unet_acc_out += transforms(outputs_unet[i,j])\n",
    "                        gunet_acc_out += transforms(outputs_gunet[i,j])\n",
    "                        acc_tar += transforms(targets[i,j])\n",
    "                    count +=1\n",
    "    return acc_tar/count, unet_acc_out/count, gunet_acc_out/count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_fourier, unet_fourier, gunet_fourier = accumulate_fourier(loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebfa273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, window_size=32):\n",
    "    window = np.ones((window_size,window_size)) / (window_size**2)\n",
    "    \n",
    "    return scipy.signal.convolve2d(arr, window, mode='same')\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,4),dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "\n",
    "r = range(0, gunet_fourier.shape[1])\n",
    "p = range(0, gunet_fourier.shape[0])\n",
    "X, Y = np.meshgrid(r, p)\n",
    "\n",
    "z1 = moving_average(np.log(np.abs(tar_fourier.cpu())))\n",
    "z2 = moving_average(np.log(np.abs(unet_fourier.cpu())))\n",
    "z3 = moving_average(np.log(np.abs(gunet_fourier.cpu())))\n",
    "vmin=0.9\n",
    "vmax=1.8\n",
    "print(vmin,vmax)\n",
    "# ax1.plot_surface(X, Y, abs(z1-z1), cmap='turbo', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "s = axs[0].plot_surface(X, Y, abs(z2-z1), cmap='RdYlGn_r', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "axs[1].plot_surface(X, Y, abs(z3-z1), cmap='RdYlGn_r', vmin=vmin,vmax=vmax, cstride=4, rstride=4)\n",
    "\n",
    "for ax, title in zip(axs, [\"UNet\", \"GUNet\"]):\n",
    "    ax.set_proj_type('ortho') \n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "    ax.set_zlim(0, vmax+0.5)\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (0.8,0.8,0.8,1)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (0.8,0.8,0.8,1)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (0.8,0.8,0.8,1)\n",
    "    ax.set_title(r\"$\\bf{\"+f\"{title}\"+\"}$\")\n",
    "#     ax.axis('off')\n",
    "    \n",
    "fig.tight_layout(pad=0)\n",
    "fig.colorbar(s, ax=axs,shrink=0.5,location='bottom', orientation='horizontal',pad=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8,4),dpi=200)\n",
    "# axs[0].imshow(z1,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[0].imshow(abs(z2-z1),vmin=vmin,vmax=vmax,cmap='RdYlGn_r')\n",
    "axs[1].imshow(abs(z3-z1),vmin=vmin,vmax=vmax,cmap='RdYlGn_r')\n",
    "\n",
    "for ax, title in zip(axs, [\"UNet\", \"GUNet\"]):\n",
    "    ax.set_title(r\"$\\bf{\"+f\"{title}\"+\"}$\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "fig.tight_layout(pad=1)\n",
    "fig.colorbar(s, ax=axs,shrink=0.5,location='bottom', orientation='horizontal',pad=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin=9.5\n",
    "vmax=16\n",
    "\n",
    "pad_x = 75\n",
    "pad_y = 65\n",
    "window = 8\n",
    "\n",
    "z1 = moving_average(np.log(np.abs(tar_fourier.cpu())),window )\n",
    "z2 = moving_average(np.log(np.abs(unet_fourier.cpu())),window )\n",
    "z3 = moving_average(np.log(np.abs(gunet_fourier.cpu())),window )\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(9,3),dpi=200)\n",
    "s = axs[0].imshow(z1,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[1].imshow(z2,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "axs[2].imshow(z3,vmin=vmin,vmax=vmax,cmap='turbo')\n",
    "\n",
    "for ax, title in zip(axs, [\"Targets\", \"UNet\", \"GUNet\"]):\n",
    "    ax.set_title(r\"$\\bf{\"+f\"{title}\"+\"}$\")\n",
    "    ax.axis('off')\n",
    "#     ax.grid(0.8)\n",
    "#     ax.set_frame_on(False)\n",
    "#     ax.set_xticks([544/2-pad_x,544/2+pad_x])\n",
    "#     ax.set_yticks([352/2-pad_y,352/2+pad_y])\n",
    "    \n",
    "    \n",
    "fig.tight_layout(pad=0.4)\n",
    "fig.colorbar(s, ax=axs,shrink=0.5,location='bottom', orientation='horizontal',pad=0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca78a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(arr0.flatten(),arr1.flatten(),equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5785e4-c785-4d18-b349-3dd88d5b5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_loss = pytorch_ssim.SSIM()\n",
    "test_loader = iter(DataLoader(dataset, batch_size=gunet_config['batch_size'], shuffle=True, num_workers=4,))\n",
    "model = gunet_model\n",
    "with torch.no_grad():\n",
    "    (inputs, targets) = next(test_loader)\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    print(ssim_loss(outputs, targets).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255e193-e210-484a-ba4a-05a95d46b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1 import Grid\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_training = pd.read_csv('./run/unet_without_clr/training.csv')\n",
    "unet_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunet_training = pd.read_csv('./run/gunet_without_clr/training.csv')\n",
    "gunet_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SSIM: {unet_training[\"val_ssim_loss\"].max():.4f}, MSE: {unet_training[\"val_mse_loss\"].min():.7f}, MAE: {unet_training[\"val_mae_loss\"].min():.5f}')\n",
    "print(f'SSIM: {gunet_training[\"val_ssim_loss\"].max():.4f}, MSE: {gunet_training[\"val_mse_loss\"].min():.7f}, MAE: {gunet_training[\"val_mae_loss\"].min():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899b22c-e242-46c1-8aec-89a8e75c9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=200,figsize=(3,3))\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "unet_training['delta'] = [dt.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in unet_training['time']]\n",
    "unet_training['delta']  = [(t - unet_training['delta'][0]).total_seconds() for t in unet_training['delta']]\n",
    "gunet_training['delta'] = [dt.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in gunet_training['time']]\n",
    "gunet_training['delta']  = [(t - gunet_training['delta'][0]).total_seconds() for t in gunet_training['delta']]\n",
    "\n",
    "\n",
    "ax.plot(unet_training['delta'],unet_training['val_ssim_loss'],c=\"#268BD2\",label='Unet')\n",
    "ax.plot(gunet_training['delta'],gunet_training['val_ssim_loss'],c=\"#D1495B\",label='GUnet')\n",
    "\n",
    "ax.set_xlabel('Duration (hours)')\n",
    "ax.set_ylabel('SSIM')\n",
    "\n",
    "\n",
    "# y_ticks = np.arange(0.81, 0.875, 0.01)\n",
    "# plt.yticks(y_ticks,[round(i,3)  for i in y_ticks])\n",
    "ax.set_xticks([i * 86400 for i in np.arange(0,3.5,0.5)])\n",
    "ax.set_xticklabels([f\"{round(i // 3600)}\" for i in ax.get_xticks()])\n",
    "ax.set_ylim(0.825,0.873)\n",
    "\n",
    "ax.legend(framealpha=1)\n",
    "ax.grid(True,c='0.8')\n",
    "ax.set_frame_on(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=200,figsize=(3,3))\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "ax.plot(unet_training['epoch']+1,unet_training['val_ssim_loss'],c=\"#268BD2\",label='Unet')\n",
    "ax.plot(gunet_training['epoch']+1,gunet_training['val_ssim_loss'],c=\"#D1495B\",label='GUnet')\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('SSIM')\n",
    "\n",
    "# y_ticks = np.arange(0.825, 0.875, 0.01)\n",
    "# plt.yticks(y_ticks,[round(i,3) if round(i,4) % 0.001 == 0 else \"\"  for i in y_ticks])\n",
    "# ax.set_xticks([i * 86400 for i in np.arange(0,3.5,0.5)])\n",
    "# ax.set_xticklabels([f\"{round(i // 3600)}\" for i in ax.get_xticks()])\n",
    "ax.set_ylim(0.825,0.875)\n",
    "\n",
    "ax.legend(framealpha=1)\n",
    "ax.grid(True,c='0.8')\n",
    "ax.set_frame_on(False)\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullLocator, NullFormatter\n",
    "\n",
    "fig, ax = plt.subplots(1,1,dpi=200,figsize=(3,3))\n",
    "\n",
    "ax.plot(unet_training['epoch']+1,unet_training['val_mae_loss'] ,c=\"#268BD2\",label='Unet validation')\n",
    "ax.plot(gunet_training['epoch']+1,gunet_training['val_mae_loss'] ,c=\"#D1495B\",label='GUNet validation')\n",
    "# # set the axis labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MAE')\n",
    "\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "y_min, y_max = 0.0125, 0.0185\n",
    "num_ticks = 10\n",
    "y_ticks = np.round(np.logspace(np.log10(y_min), np.log10(y_max),5),5)\n",
    "ax.set_yticks(y_ticks)\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "ax.yaxis.set_minor_locator(NullLocator())\n",
    "ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "ax.set_ylim(y_min,y_max)\n",
    "ax.legend(loc='upper right',framealpha=1)\n",
    "\n",
    "ax.grid(True,c='0.8')\n",
    "ax.set_frame_on(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5a963",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullLocator, NullFormatter\n",
    "\n",
    "fig, ax = plt.subplots(1,1,dpi=200,figsize=(3,3))\n",
    "\n",
    "ax.plot(unet_training['epoch']+1,unet_training['train_mse_loss'],c=\"#268BD2\",linestyle=':' ,label='UNet training')\n",
    "ax.plot(unet_training['epoch']+1,unet_training['val_mse_loss'] ,c=\"#268BD2\",label='Unet validation')\n",
    "ax.plot(gunet_training['epoch']+1,gunet_training['train_mse_loss'],c=\"#D1495B\",linestyle=':' ,label='GUNet training')\n",
    "ax.plot(gunet_training['epoch']+1,gunet_training['val_mse_loss'] ,c=\"#D1495B\",label='GUNet validation')\n",
    "# # set the axis labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "y_min, y_max = 0.0017, 0.00301\n",
    "num_ticks = 10\n",
    "y_ticks = np.round(np.logspace(np.log10(0.0017), np.log10(0.003),5),5)\n",
    "ax.set_yticks(y_ticks)\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "ax.yaxis.set_minor_locator(NullLocator())\n",
    "ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "ax.set_ylim(0.0017,0.003)\n",
    "ax.legend(loc='upper right',framealpha=1)\n",
    "\n",
    "ax.grid(True,c='0.8')\n",
    "ax.set_frame_on(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a63d4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "test_loader = iter(DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4,))\n",
    "\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ssim_loss = pytorch_ssim.SSIM()\n",
    "mae_loss = nn.L1Loss()\n",
    "losses = [mae_loss,mse_loss,ssim_loss]\n",
    "\n",
    "gunet_losses = np.zeros((batch_size,dataset_config['output_length'],len(losses)))\n",
    "unet_losses = np.zeros((batch_size,dataset_config['output_length'],len(losses)))\n",
    "            \n",
    "with torch.no_grad():\n",
    "    (inputs, targets) = next(test_loader)\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    gunet_outputs = gunet_model(inputs)\n",
    "    unet_outputs = unet_model(inputs)\n",
    "    \n",
    "    for i in range(targets.shape[0]):\n",
    "        for j in range(targets.shape[1]):\n",
    "            for k in range(len(losses)):\n",
    "                gunet_losses[i,j,k] = losses[k](gunet_outputs[i,j].unsqueeze(0).unsqueeze(0), targets[i,j].unsqueeze(0).unsqueeze(0)).item()\n",
    "                unet_losses[i,j,k] = losses[k](unet_outputs[i,j].unsqueeze(0).unsqueeze(0), targets[i,j].unsqueeze(0).unsqueeze(0)).item()\n",
    "            \n",
    "#     for i, loss in zip([mse_loss,]):\n",
    "#                 running_losses[i] += \n",
    "    \n",
    "    max_vals, max_idxs = torch.max(targets, dim=3)\n",
    "    max_vals, max_idxs = torch.max(max_vals, dim=2)\n",
    "    max_vals, max_idxs = torch.max(max_vals, dim=1)\n",
    "    mean_vals = torch.mean(targets, dim=3)\n",
    "    mean_vals = torch.mean(mean_vals, dim=2)\n",
    "    mean_vals = torch.mean(mean_vals, dim=1)\n",
    "    ssim_vals = torch.mean(torch.tensor(gunet_losses[:,:,2]), dim=1)\n",
    "    sorted_max = torch.sort(max_vals,descending=True).indices\n",
    "    sorted_mean = torch.sort(mean_vals,descending=True).indices\n",
    "    sorted_ssim = torch.sort(ssim_vals,descending=True).indices\n",
    "iterator_max = iter(sorted_max)\n",
    "iterator_mean = iter(sorted_mean)\n",
    "print(ssim_vals,sorted_ssim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de581042",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_i = 2\n",
    "max_i = 0\n",
    "max_diff = gunet_losses[0,0,loss_i] - unet_losses[0,0,loss_i]\n",
    "for i in range(batch_size):\n",
    "        for j in range(dataset_config['output_length']):\n",
    "            tmp_diff = gunet_losses[i,j,loss_i] - unet_losses[i,j,loss_i]\n",
    "            if tmp_diff > max_diff:\n",
    "                max_diff = tmp_diff\n",
    "                max_i = i\n",
    "print(max_i, max_diff)\n",
    "max_j = max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_max = iter(sorted_max)\n",
    "iterator_mean = iter(sorted_mean[10:])\n",
    "iterator_ssim = iter(sorted_ssim[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2defd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_j = next(iterator_ssim).item()\n",
    "print(max_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86aaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0c753",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.colors as colors\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "coor = (11.8, 48.07, 19.41, 51.57)\n",
    "\n",
    "idx = [1,3,5,7]\n",
    "# ratio = targets[0,0].shape[0]/targets[0,0].shape[1]\n",
    "ratio = 352/544\n",
    "\n",
    "llcrnrlon, llcrnrlat, urcrnrlon, urcrnrlat = coor\n",
    "lat_1 = (llcrnrlat + urcrnrlat) / 2.0\n",
    "lon_0 = (llcrnrlon + urcrnrlon) / 2.0\n",
    "\n",
    "# create the Basemap object\n",
    "m = Basemap(llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat,\n",
    "            urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat,\n",
    "            resolution='i', projection='aea', lat_1=lat_1, lon_0=lon_0)\n",
    "fig,axs = plt.subplots(len(idx),3, dpi=300, figsize=(3*3,3*len(idx)), height_ratios=[ratio for i in idx])\n",
    "\n",
    "cmap = 'turbo'\n",
    "\n",
    "# max_j = next(iterator_mean).item()\n",
    "# max_j = next(iterator_max).item()\n",
    "# max_j = next(iterator_ssim).item()\n",
    "\n",
    "low = 0.3\n",
    "high = 0.6\n",
    "# high = torch.max(targets[max_j]).item()\n",
    "\n",
    "def modified_sigmoid(x):\n",
    "#     return torch.where(x > a, 1, x/a)\n",
    "    return torch.where(x > high, 1, \n",
    "                       torch.where(x < low, 0.05,  \n",
    "                                   torch.tanh((4*torch.tensor(math.pi) / (high-low)) * (x-low))))\n",
    "#     return torch.where(x > a, 1, 1 / (1 + np.exp(-k * (x - a/2))))\n",
    "#     return 1 / (1 + np.exp(-k * (x - a)))\n",
    "\n",
    "for i, image_idx in enumerate(idx):\n",
    "#     m.arcgisimage(ax=axs[i,0], service='Canvas/World_Light_Gray_Base',xpixels=1000)\n",
    "#     m.arcgisimage(ax=axs[i,1], service='Canvas/World_Light_Gray_Base',xpixels=1000)\n",
    "#     m.arcgisimage(ax=axs[i,2], service='Canvas/World_Light_Gray_Base',xpixels=1000)\n",
    "    m.drawcountries(linewidth=.5, ax=axs[i,0],zorder=-10,color='gray')\n",
    "    m.drawcountries(linewidth=.5, ax=axs[i,1],zorder=-10,color='gray')\n",
    "    m.drawcountries(linewidth=.5, ax=axs[i,2],zorder=-10,color='gray')\n",
    "    axs[i,1].set_xlabel(r\"$\\bf{SSIM}: $\" + f\"{gunet_losses[max_j,i,2]:.3f}, \" + \n",
    "                        r\"$\\bf{MAE}: $\" + f\"{gunet_losses[max_j,i,0]:.4f}, \" +\n",
    "                        r\"$\\bf{MSE}: $\" + f\"{gunet_losses[max_j,i,1]:.4f}\",labelpad=0)\n",
    "    axs[i,2].set_xlabel(r\"$\\bf{SSIM}: $\" + f\"{unet_losses[max_j,i,2]:.3f}, \" + \n",
    "                        r\"$\\bf{MAE}: $\" + f\"{unet_losses[max_j,i,0]:.4f}, \" +\n",
    "                        r\"$\\bf{MSE}: $\" + f\"{unet_losses[max_j,i,1]:.4f}\",labelpad=0)\n",
    "    im = m.imshow(targets[max_j,image_idx].cpu(),\n",
    "             cmap=cmap, \n",
    "             vmin=low,vmax=high,\n",
    "#              vmin=torch.min(targets).item(),vmax=torch.max(targets).item(),\n",
    "             ax=axs[i,0], \n",
    "             origin='upper',\n",
    "             alpha=modified_sigmoid(targets[max_j,image_idx].cpu()))\n",
    "    \n",
    "    m.imshow(gunet_outputs[max_j,image_idx].cpu(),\n",
    "             cmap=cmap, \n",
    "             vmin=low,vmax=high,\n",
    "#              vmin=torch.min(gunet_outputs).item(),vmax=torch.max(gunet_outputs).item(),\n",
    "             ax=axs[i,1],\n",
    "             origin='upper',\n",
    "             alpha=modified_sigmoid(gunet_outputs[max_j,image_idx].cpu()),)\n",
    "    \n",
    "    m.imshow(unet_outputs[max_j,image_idx].cpu(),\n",
    "             cmap=cmap,\n",
    "             vmin=low, vmax=high,\n",
    "#              vmin=torch.min(unet_outputs).item(),vmax=torch.max(unet_outputs).item(),\n",
    "             ax=axs[i,2],\n",
    "             origin='upper', \n",
    "             alpha=modified_sigmoid(unet_outputs[max_j,image_idx ].cpu()))\n",
    "    \n",
    "for axs2 in axs:\n",
    "    for ax in axs2:\n",
    "        ax.set_frame_on(False)\n",
    "        \n",
    "fig.tight_layout(pad=0.2)\n",
    "cbar = fig.colorbar(im, ax=axs[:,:],shrink=0.5,location='bottom', orientation='horizontal',pad=0.03, aspect=15)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "for ax, idx in zip(axs[:,0], idx):\n",
    "    ax.set_ylabel(r\"T +$\\bf{\"+f\"{(idx+1)*10}\"+\"}$ min\", fontsize=16,labelpad=0)\n",
    "    \n",
    "for ax, title in zip(axs[0], [\"Observation\", \"GUNet\", \"UNet\"]):\n",
    "    ax.set_title(r\"$\\bf{\"+f\"{title}\"+\"}$\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_j = next(iterator_mean).item()\n",
    "max_j = 47\n",
    "print(max_j)\n",
    "\n",
    "\n",
    "ratio = 352/544\n",
    "\n",
    "fig,axs = plt.subplots(1,2,dpi=200,figsize=(2*10*ratio,10))\n",
    "llcrnrlon, llcrnrlat, urcrnrlon, urcrnrlat = coor\n",
    "lat_1 = (llcrnrlat + urcrnrlat) / 2.0\n",
    "lon_0 = (llcrnrlon + urcrnrlon) / 2.0\n",
    "\n",
    "# create the Basemap object\n",
    "m = Basemap(llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat,\n",
    "            urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat,\n",
    "            resolution='i', projection='aea', lat_1=lat_1, lon_0=lon_0)\n",
    "\n",
    "\n",
    "m.scatter(13.8178, 49.6583, 25, ax=axs[0], latlon=True, marker='x', color='Black',linewidths=1) \n",
    "m.scatter(13.8178, 49.6583, 25, ax=axs[1], latlon=True, marker='x', color='Black',linewidths=1) \n",
    "m.scatter(16.7885, 49.5011, 25, ax=axs[0], latlon=True, marker='+', color='Black',linewidths=1) \n",
    "m.scatter(16.7885, 49.5011, 25, ax=axs[1], latlon=True, marker='+', color='Black',linewidths=1) \n",
    "\n",
    "\n",
    "# m.arcgisimage(ax=axs[0], service='Reference/World_Boundaries_and_Places_Alternate',xpixels=1000)\n",
    "# m.arcgisimage(ax=axs[1], service='Reference/World_Boundaries_and_Places_Alternate',xpixels=1000)\n",
    "\n",
    "m.drawcountries(linewidth=.5, ax=axs[0],color='gray')\n",
    "m.drawcountries(linewidth=.5, ax=axs[1],color='gray')\n",
    "\n",
    "low=0\n",
    "high=1\n",
    "\n",
    "im = m.imshow(targets[47,0].cpu(),\n",
    "             cmap=cmap, \n",
    "             vmin=low,vmax=high,\n",
    "             ax=axs[0],\n",
    "             origin='upper',\n",
    "             alpha=modified_sigmoid(targets[47,0].cpu()))\n",
    "\n",
    "im = m.imshow(targets[21,0].cpu(),\n",
    "             cmap=cmap, \n",
    "             vmin=low,vmax=high,\n",
    "             ax=axs[1],\n",
    "             origin='upper',\n",
    "             alpha=modified_sigmoid(targets[21,0].cpu()))\n",
    "\n",
    "axs[0].set_frame_on(False)\n",
    "axs[1].set_frame_on(False)\n",
    "\n",
    "fig.tight_layout(pad=0.3)\n",
    "fig.colorbar(im, ax=axs,shrink=0.3,location='bottom', orientation='horizontal',pad=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distinct_values(tensor, epsilon):\n",
    "    print(\".\")\n",
    "    \n",
    "    sorted_tensor = np.sort(np.unique(tensor.cpu().numpy()))\n",
    "    print(\".\")\n",
    "    \n",
    "    diffs = np.diff(sorted_tensor)\n",
    "    print(\".\")\n",
    "    \n",
    "    distinct_indices = np.where(diffs >= epsilon)[0]\n",
    "    print(\".\")\n",
    "    \n",
    "    distinct_values = sorted_tensor[np.concatenate(([0], distinct_indices + 1))]\n",
    "    \n",
    "    return distinct_values\n",
    "\n",
    "distinct = find_distinct_values(torch.flatten(inputs),0.0000001) * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f31e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means = []\n",
    "medians = []\n",
    "max_values = []\n",
    "\n",
    "for tensor,_ in tqdm(test_loader, desc=\"Computing histograms\"):\n",
    "    means_batch = torch.mean(tensor.view(tensor.shape[0], tensor.shape[1], -1), dim=-1).flatten().tolist()\n",
    "    medians_batch = torch.median(tensor.view(tensor.shape[0], tensor.shape[1], -1), dim=-1).values.flatten().tolist()\n",
    "    max_values_batch = torch.max(tensor.view(tensor.shape[0], tensor.shape[1], -1), dim=-1).values.flatten().tolist()\n",
    "    \n",
    "    means.extend(means_batch)\n",
    "    medians.extend(medians_batch)\n",
    "    max_values.extend(max_values_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cdcbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins=16\n",
    "combined_histogram = torch.zeros(num_bins)\n",
    "for inputs,targets in tqdm(train_loader, desc=\"Computing histograms\"):\n",
    "    histogram = torch.histc(inputs, bins=num_bins, min=0, max=1)\n",
    "    combined_histogram += histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( figsize=(3,2),dpi=200)\n",
    "# fig.patch.set_facecolor('black')\n",
    "\n",
    "df = pd.DataFrame({\"median\":medians,\"mean\":means,\"max\":max_values})\n",
    "columns = df.columns\n",
    "x_step = 0.1\n",
    "y_step = 0.05\n",
    "\n",
    "colors= [\"#268BD2\",\"#EDAE49\",\"#D1495B\"]\n",
    "\n",
    "polygons = []\n",
    "\n",
    "m_min = 0\n",
    "m_max = len(train_loader)*8\n",
    "\n",
    "# for i,column in enumerate(columns):\n",
    "#     vals , bins = np.histogram(df[column],bins=num_bins)\n",
    "#     m_min = np.min(np.append(vals,m_min))\n",
    "#     m_max = np.max(np.append(vals,m_max))\n",
    "\n",
    "    \n",
    "num_bins = 16\n",
    "for i,column in enumerate(columns):\n",
    "    vals , bins = np.histogram(df[column],bins=num_bins)\n",
    "    bins = (bins - np.min(bins))/(np.max(bins)-np.min(bins))\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    x = np.zeros(num_bins+2)\n",
    "    y = np.zeros(num_bins+2)\n",
    "    \n",
    "    x[0] = np.min(bin_centers)\n",
    "    x[num_bins+1] = np.max(bin_centers)\n",
    "    \n",
    "    x[1:num_bins+1] =  bin_centers\n",
    "\n",
    "    y[1:num_bins+1] = (vals - m_min)/(m_max-m_min)\n",
    "    polygon = Polygon(np.c_[x+i*x_step, y+i*y_step], fc=colors[i], ec='0', lw=1,closed=False, zorder=-i, alpha=1)\n",
    "    polygons.append(polygon)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "ax.axis('tight')\n",
    "# ax.set_facecolor(\"black\")\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "ax.set_yticks(np.linspace(0,1,6))\n",
    "\n",
    "ax.set_xticks(np.linspace(0,1,6))\n",
    "ax.set_xticklabels(np.around(np.linspace(0,1,6),1))\n",
    "\n",
    "ax.set_xlabel('Pixel Value')\n",
    "ax.set_ylabel('Fraction of images')\n",
    "ax.legend(polygons,columns,loc='upper right',framealpha=1)\n",
    "\n",
    "\n",
    "for t in ax.get_yticks():\n",
    "    ax.plot([0,(len(columns)-1)*x_step], [ t, t + (len(columns)-1)*y_step],\n",
    "            '0.8',zorder=-10,lw=1)\n",
    "\n",
    "# for t in ax.get_yticks():\n",
    "#     ax.plot([(len(columns)-1)*x_step,1+(len(columns)-1)*x_step], [ t + (len(columns)-1)*y_step, t + (len(columns)-1)*y_step],\n",
    "#             '0.8',zorder=-10,lw=1)\n",
    "    \n",
    "for t in ax.get_xticks():\n",
    "    ax.plot([t, t + (len(columns)-1)*x_step],[0,(len(columns)-1)*y_step],\n",
    "            '0.8',zorder=-10,lw=1)\n",
    "\n",
    "# for t in ax.get_xticks():\n",
    "#     ax.plot([t + (len(columns)-1)*x_step, t + (len(columns)-1)*x_step],[(len(columns)-1)*y_step,1+(len(columns)-1)*y_step],\n",
    "#             '0.8',zorder=-10,lw=1)\n",
    "    \n",
    "fig.tight_layout(pad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8173ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,dpi=200,figsize=(3,2))\n",
    "\n",
    "bin_edges = torch.linspace(0, 1, num_bins+1)\n",
    "axs.bar(bin_centers, combined_histogram/(m_max*352*544), width=(1 - 0) / num_bins, edgecolor='black',color=\"#268BD2\")\n",
    "axs.set_xlabel('Pixel Value')\n",
    "axs.set_ylabel('Fraction of pixels')\n",
    "\n",
    "axs.set_yticks(np.linspace(0,1,6))\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# ax.spines['bottom'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "\n",
    "# axs.set_frame_on(False)\n",
    "fig.tight_layout(pad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( figsize=(5,4),dpi=200)\n",
    "# fig.patch.set_facecolor('black')\n",
    "\n",
    "df = pd.DataFrame({\"pixel_valu\":medians,\"max\":max_values,\"mean\":means})\n",
    "columns = df.columns\n",
    "x_step = 0.1\n",
    "y_step = 0.05\n",
    "\n",
    "colors= [\"#268BD2\",\"#D1495B\",\"#EDAE49\"]\n",
    "\n",
    "polygons = []\n",
    "\n",
    "m_min = np.inf\n",
    "m_max = -np.inf\n",
    "\n",
    "for i,column in enumerate(columns):\n",
    "    vals , bins = np.histogram(df[column],bins=num_bins)\n",
    "    m_min = np.min(np.append(vals,m_min))\n",
    "    m_max = np.max(np.append(vals,m_max))\n",
    "\n",
    "    \n",
    "num_bins = 16\n",
    "for i,column in enumerate(columns):\n",
    "    vals , bins = np.histogram(df[column],bins=num_bins)\n",
    "    bins = (bins - np.min(bins))/(np.max(bins)-np.min(bins))\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    x = np.zeros(num_bins+2)\n",
    "    y = np.zeros(num_bins+2)\n",
    "    \n",
    "    x[0] = np.min(bin_centers)\n",
    "    x[num_bins+1] = np.max(bin_centers)\n",
    "    \n",
    "    x[1:num_bins+1] =  bin_centers\n",
    "\n",
    "    y[1:num_bins+1] = (vals - m_min)/(m_max-m_min)\n",
    "    polygon = Polygon(np.c_[x+i*x_step, y+i*y_step], fc=colors[i], ec='0', lw=1,closed=False, zorder=-i, alpha=1)\n",
    "    polygons.append(polygon)\n",
    "    ax.add_patch(polygon)\n",
    "\n",
    "ax.axis('tight')\n",
    "# ax.set_facecolor(\"black\")\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "ax.set_yticks(np.linspace(0,1,6))\n",
    "\n",
    "ax.set_xticks(np.linspace(0,1,6))\n",
    "ax.set_xticklabels(np.around(np.linspace(0,1,6),1))\n",
    "\n",
    "ax.set_xlabel('Pixel Value')\n",
    "ax.set_ylabel('Fraction of images in the dataset')\n",
    "ax.legend(polygons,columns,loc='right')\n",
    "\n",
    "\n",
    "for t in ax.get_yticks():\n",
    "    ax.plot([0,(len(columns)-1)*x_step], [ t, t + (len(columns)-1)*y_step],\n",
    "            '0.8',zorder=-10,lw=0.5)\n",
    "    \n",
    "for t in ax.get_xticks():\n",
    "    ax.plot([t, t + (len(columns)-1)*x_step],[0,(len(columns)-1)*y_step],\n",
    "            '0.8',zorder=-10,lw=0.5)\n",
    "    \n",
    "fig.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5ebd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
